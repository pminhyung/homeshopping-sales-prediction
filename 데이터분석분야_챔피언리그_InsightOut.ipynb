{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 빅콘테스트 2020 - [챔피언리그] NS SHOP+ 판매실적 예측을 통한 편성 최적화 방안(모형) 도출\n",
    "  \n",
    "## 팀명: InsightOut\n",
    "- 팀장 : 박민형(pminhyung12@naver.com)\n",
    "- 팀원 : 김우용(zxc1843zzz@naver.com), 박서희(seohuipark95@gmail.com), 문찬호(buddy6274@naver.com)\n",
    "  \n",
    "## 코드 순서\n",
    "- 패키지 및 라이브러리 Import\n",
    "- 함수생성 - 데이터 불러오기 및 병합\n",
    "- 함수실행 - 데이터 불러오기 및 병합\n",
    "- 모델적합을 위한 **변수선택과 파이프라인 함수 생성**\n",
    "- KNN Imputation\n",
    "- 상품명(pdname) 벡터화\n",
    "- 학습을 위한 최종데이터셋 정의\n",
    "- 하이퍼파라미터 최적화 - 베이지안 최적화\n",
    "- 모델학습 - **LightGBM**\n",
    "- 제출파일 생성 - (2020. 06) 테스트 데이터 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 패키지 및 라이브러리 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: soynlp in c:\\users\\jasonpark\\anaconda3\\envs\\tensorflow\\lib\\site-packages (0.0.493)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\jasonpark\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from soynlp) (1.4.1)\n",
      "Requirement already satisfied: numpy>=1.12.1 in c:\\users\\jasonpark\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from soynlp) (1.18.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\jasonpark\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from soynlp) (0.22.2.post1)\n",
      "Requirement already satisfied: psutil>=5.0.1 in c:\\users\\jasonpark\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from soynlp) (5.7.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\jasonpark\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from scikit-learn>=0.20.0->soynlp) (0.14.1)\n",
      "Requirement already satisfied: lightgbm in c:\\users\\jasonpark\\anaconda3\\envs\\tensorflow\\lib\\site-packages (2.3.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\jasonpark\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from lightgbm) (1.18.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\jasonpark\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from lightgbm) (0.22.2.post1)\n",
      "Requirement already satisfied: scipy in c:\\users\\jasonpark\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from lightgbm) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\jasonpark\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from scikit-learn->lightgbm) (0.14.1)\n",
      "Requirement already satisfied: bayesian-optimization in c:\\users\\jasonpark\\anaconda3\\envs\\tensorflow\\lib\\site-packages (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.9.0 in c:\\users\\jasonpark\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from bayesian-optimization) (1.18.2)\n",
      "Requirement already satisfied: scipy>=0.14.0 in c:\\users\\jasonpark\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from bayesian-optimization) (1.4.1)\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in c:\\users\\jasonpark\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from bayesian-optimization) (0.22.2.post1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\jasonpark\\anaconda3\\envs\\tensorflow\\lib\\site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (0.14.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install soynlp\n",
    "!pip install lightgbm\n",
    "!pip install bayesian-optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy: 1.18.2\n",
      "pandas: 1.0.3\n",
      "soynlp: 0.0.493\n",
      "sklearn: 0.22.2.post1\n",
      "lightgbm: 2.3.1\n"
     ]
    }
   ],
   "source": [
    "### [데이터 전처리를 위한 라이브러리 및 모듈]\n",
    "import os\n",
    "import string\n",
    "import re\n",
    "from functools import reduce\n",
    "from datetime import datetime, timedelta, date\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soynlp\n",
    "from soynlp.tokenizer import RegexTokenizer\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "### [머신러닝을 위한 라이브러리 및 모듈]\n",
    "import sklearn\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "import lightgbm\n",
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "### [서드파티 패키지 버전확인]\n",
    "print('numpy:', np.__version__)\n",
    "print('pandas:', pd.__version__)\n",
    "print('soynlp:', soynlp.__version__)\n",
    "print('sklearn:', sklearn.__version__)\n",
    "print('lightgbm:', lightgbm.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수생성 - 데이터 불러오기 및 병합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### [2019, 2020 공휴일 리스트]\n",
    "hday_19 = [i.replace(' ','-') for i in ['2019 01 01', '2019 02 04', '2019 02 05', '2019 02 06', '2019 03 01', '2019 05 06', '2019 06 06',\n",
    "'2019 08 15', '2019 09 12', '2019 08 13', '2019 10 03', '2019 10 09', '2019 12 25', '2020 01 01',]]\n",
    "\n",
    "hday_20 = [i.replace(' ','-') for i in ['2020 06 06']]\n",
    "### //\n",
    "\n",
    "### [함수 생성 - 데이터 적재]\n",
    "def load_NS():\n",
    "    train = pd.read_excel('train/sales_train.xlsx', skiprows=1)\n",
    "    test = pd.read_excel('test/sales_test.xlsx', skiprows=1)\n",
    "    return train, test\n",
    "\n",
    "\n",
    "def load_categories(train=True):     # 상품카테고리 및 네이버데이터랩 데이터\n",
    "    if train:\n",
    "        cat = pd.read_csv('train_category_datalab.csv')[['ratio', 'sub_cate']]\n",
    "        cat.columns = ['ratio', 'sub_cate']\n",
    "        return cat\n",
    "    else:\n",
    "        cat = pd.read_csv('test_category_datalab.csv')[['ratio', '세분류']]\n",
    "        cat.columns = ['ratio', 'sub_cate']\n",
    "        return cat\n",
    "\n",
    "    \n",
    "def load_weather(train=True):        # 기상 데이터\n",
    "    if train:\n",
    "        return pd.read_csv('2019_weather_dust.csv')\n",
    "    else:\n",
    "        return pd.read_csv('2020_weather_dust.csv')\n",
    "\n",
    "    \n",
    "def load_kosis(path, ind_col):       # KOSIS 데이터\n",
    "    df = pd.read_excel(path, index_col = ind_col).T.reset_index()\n",
    "    df['index'] = df['index'].apply(lambda x: x.replace('. ', '-'))\n",
    "    df.columns = [col_name.strip() for col_name in df.columns]\n",
    "    return df\n",
    "\n",
    "\n",
    "def load_parcel():                   # 배송 데이터\n",
    "    parcel = pd.read_csv('delivery.csv')[['period', 'delivery']]\n",
    "    parcel.columns = ['dt_YMD', 'parcel']\n",
    "    return parcel\n",
    "\n",
    "\n",
    "def load_mask():                     # 마스크 데이터\n",
    "    mask = pd.read_csv('mask.csv')[['period', 'ratio']]\n",
    "    mask.columns = ['dt_YMD', 'mask']\n",
    "    return mask\n",
    "\n",
    "### //\n",
    "\n",
    "\n",
    "### [함수 생성 - 필요 변수 생성]\n",
    "def preprocess_NS(df, hday):\n",
    "    df.columns = ['datetime', 'duration', 'mthcode', 'pdcode', 'pdname', 'pdgroup','unitp', 'sales']\n",
    "\n",
    "    \n",
    "    # [날짜시간 관련 변수]\n",
    "    t = ['mon', 'tue', 'wed', 'thur', 'fri', 'sat', 'sun']\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df['mth'] = df['datetime'].dt.month\n",
    "    df['day'] = df['datetime'].dt.day\n",
    "    df['hour'] = df['datetime'].dt.hour\n",
    "    df['minute'] = df['datetime'].dt.minute\n",
    "    df['dt_YMD'] = df['datetime'].apply(lambda x: str(x).split()[0])\n",
    "    df['wday_num'] = df['datetime'].apply(lambda x: x.weekday())\n",
    "    df['wday'] = df['datetime'].apply(lambda x: t[x.weekday()])\n",
    "    df['hday'] = df['wday'].apply(lambda x: 0)\n",
    "    df.loc[(df['dt_YMD'].isin(hday)) | (df['wday'].isin(['sat', 'sun'])), 'hday'] = 1\n",
    "    df['hour_168'] = df['wday_num']*24 + df['hour']\n",
    "    df['week_52'] = df['datetime'].apply(lambda x: date(x.year, x.month, x.day).isocalendar()[1] if x < pd.to_datetime('2019-12-30') else 53)\n",
    "    \n",
    "    \n",
    "    # [프라임타임 binning 변수]\n",
    "    df['prime']=0\n",
    "    week_prime_morn = [9, 10, 11]\n",
    "    week_prime_aft = [16, 17]\n",
    "    week_prime_even = [20, 21, 22]\n",
    "    week_not_prime = [1,2,3,4,5,6,7,8,12,13,14,15,18,19,23,24]\n",
    "    wknd_prime_morn = [8,9,10,11]\n",
    "    wknd_prime_aft = [13,14,15,16,17]\n",
    "    wknd_prime_even = [21,22]\n",
    "    wknd_not_prime = [1,2,3,4,5,6,7,12,18,19,20,23,24]\n",
    "    \n",
    "    df.loc[(df['hday']==0)&(df['hour'].isin(week_prime_morn)), 'prime'] = 'week_prime_morn'\n",
    "    df.loc[(df['hday']==0)&(df['hour'].isin(week_prime_aft)), 'prime'] = 'week_prime_aft'\n",
    "    df.loc[(df['hday']==0)&(df['hour'].isin(week_prime_even)), 'prime'] = 'week_prime_even'\n",
    "    df.loc[(df['hday']==0)&(df['hour'].isin(week_not_prime)), 'prime'] = 'week_not_prime'\n",
    "    df.loc[(df['hday']==1)&(df['hour'].isin(wknd_prime_morn)), 'prime'] = 'wknd_prime_morn'\n",
    "    df.loc[(df['hday']==1)&(df['hour'].isin(wknd_prime_aft)), 'prime'] = 'wknd_prime_aft'\n",
    "    df.loc[(df['hday']==1)&(df['hour'].isin(wknd_prime_even)), 'prime'] = 'wknd_prime_even'\n",
    "    df.loc[(df['hday']==1)&(df['hour'].isin(wknd_not_prime)), 'prime'] = 'wknd_not_prime'\n",
    "    \n",
    "    \n",
    "    # [단위가격 binning 변수] \n",
    "    bin_divider=[0, df.unitp.quantile(.25), df.unitp.quantile(.5),\\\n",
    "                 df.unitp.quantile(.75), df.unitp.max()]\n",
    "                 \n",
    "    bin_names=['low_price','mid_low_price','mid_high_price','high_price']\n",
    "\n",
    "    df['unitp_bin']=pd.cut(x=df['unitp'], \n",
    "                   bins=bin_divider, \n",
    "                   labels=bin_names, \n",
    "                   include_lowest=True) \n",
    "    \n",
    "    df['orders']=df['sales']/df['unitp']\n",
    "    \n",
    "    \n",
    "    # [zapping-time 관련 변수]\n",
    "    duration_df = df.pivot_table(index = ['datetime'], values = 'duration', aggfunc = 'max').reset_index()\n",
    "    duration_df.columns = ['datetime', 'duration_filled']\n",
    "    df = pd.merge(df, duration_df, on = 'datetime')\n",
    "    df['mid_time'] = df['datetime'] + df['duration_filled'].apply(lambda x: timedelta(minutes = x//2))\n",
    "    df['mid_hour'] = df['mid_time'].dt.hour\n",
    "    df['mid_minute'] = df['mid_time'].dt.minute\n",
    "    df['zap_hour'] = (df['mid_time'] + df['mid_minute'].apply(lambda x: timedelta(hours=x//30))).dt.hour\n",
    "    df['wday_num'] = df['datetime'].apply(lambda x: x.weekday())\n",
    "    \n",
    "    \n",
    "    # [상품명 관련 변수] \n",
    "    df['pdname_token'] = df['pdname'].apply(lambda x: [i for i in RegexTokenizer().tokenize(x) if i not in string.punctuation])\n",
    "    df['sex'] = df['pdname_token'].apply(lambda x: 'male' if ('남성' in x) or ('남아' in x) else ('female' if ('여성' in x ) or ('여아' in x) else 'unisex'))\n",
    "    df['payment'] = df['pdname_token'].apply(lambda x: 'muisa' if ('무이자' in x) or ('무' in x) else ('ilsibul' if ('일시불' in x) or ('일' in x) else 'pay'))\n",
    "    df['bargain'] = df['pdname'].apply(lambda x: 'bargain' if ('1+1' in x) or ('파격가' in x) or ('특가' in x) or ('인하' in x) or ('세일' in x) else 'same')\n",
    "    df['junior'] = df['pdname'].apply(lambda x: 1 if ('주니어' in x) or ('아동' in x) else 0)\n",
    "    j = re.compile('[\\d]+종')\n",
    "    p = re.compile('[\\d]+팩')\n",
    "    g = re.compile('[\\d]+구')\n",
    "    m = re.compile('[\\d]+미')\n",
    "    iy = re.compile('[\\d]+인용')\n",
    "    bx = re.compile('[\\d]+박스')\n",
    "    df['jong'] = df['pdname'].apply(lambda x: j.findall(x)[0].replace('종', '') if len(j.findall(x))!=0 else\n",
    "                                    (p.findall(x)[0].replace('팩', '') if len(p.findall(x))!=0 else \n",
    "                                     (g.findall(x)[0].replace('구', '') if len(g.findall(x))!=0 else\n",
    "                                      (m.findall(x)[0].replace('미', '') if len(m.findall(x))!=0 else\n",
    "                                       (iy.findall(x)[0].replace('인용', '') if len(iy.findall(x))!=0 else\n",
    "                                        (bx.findall(x)[0].replace('박스', '') if len(bx.findall(x))!=0 else 0\n",
    "                                        )\n",
    "                                       )\n",
    "                                      )\n",
    "                                     )\n",
    "                                    )\n",
    "                                   )\n",
    "    \n",
    "\n",
    "    # [방송파트 변수] \n",
    "    df['part'] = 0\n",
    "    df['part_pk'] = df['dt_YMD'] + df['pdcode'].apply(lambda x: str(x))\n",
    "\n",
    "    for pk in df['part_pk'].unique():\n",
    "        partpk_df = df[df['part_pk']==pk]\n",
    "        num = len(partpk_df)\n",
    "        df.loc[df['part_pk']==pk, 'part'] = [i/num for i in range(1, num+1)]\n",
    "        \n",
    "\n",
    "    # [Outlier 처리를 위한 다양한 변수 생성]\n",
    "    # junior, puma, dickies, uspa, season, yeonggwang, AAC, mask_pdn, hour_rank, underwear_sex\n",
    "    df['junior'] = df['pdname'].apply(lambda x: 1 if ('주니어' in x) or ('아동' in x) else 0)\n",
    "    df['puma'] = df['pdname'].apply(lambda x: 1 if ('푸마' in x) else 0)\n",
    "    df['dickies'] = df['pdname'].apply(lambda x: 1 if ('디키즈' in x) else 0)\n",
    "    df['uspa'] = df['pdname'].apply(lambda x: 1 if ('USPA' in x) else 0)\n",
    "\n",
    "    df['season'] = df['mth'].apply(lambda x : 'winter' if ((x==1) or (x==2) or (x==12)) else ('spring' if ((x==3) or (x==4) or (x==5)) else\n",
    "                                                                                                           ('summer' if ((x==6) or (x==7) or (x==8)) else\n",
    "                                                                                                            ('fall' if ((x==9) or (x==10) or (x==11)) else 0)\n",
    "                                                                                                           )))\n",
    "    df['yeonggwang'] = df['pdname'].apply(lambda x:1 if '영광' in x  else 0)\n",
    "    df['AAC'] = df['pdname'].apply(lambda x:1 if 'AAC' in x  else 0)\n",
    "    df['mask_pdn'] = df['pdname'].apply(lambda x:1 if '마스크' in x  else 0)\n",
    "\n",
    "    \n",
    "    h_hour_168 ={}\n",
    "    w_hour_168 ={}\n",
    "    \n",
    "    for i in range(2):\n",
    "        hour_rank = 0\n",
    "        dic={}\n",
    "        for hour168 in df[df['hday']==i].groupby(['hour_168']).aggregate(np.mean).sort_values(by = 'orders').index.tolist():\n",
    "            hour_rank+=1\n",
    "            dic[hour168] = hour_rank\n",
    "        if i==0:\n",
    "            w_hour_168 = dic\n",
    "        else:\n",
    "            h_hour_168 = dic\n",
    "\n",
    "\n",
    "    def input_hour_rank(row_hday, row_hour_168):\n",
    "        if row_hday==0:\n",
    "            return w_hour_168[row_hour_168]\n",
    "        else:\n",
    "            return h_hour_168[row_hour_168]\n",
    "\n",
    "    df['hour_rank'] = df.apply(lambda row: input_hour_rank(row.hday, row.hour_168), axis = 1)\n",
    "\n",
    "\n",
    "    def input_underwear_sex(row_pdgroup, row_pdname):\n",
    "        if (row_pdgroup=='속옷') & (('드로즈' in row_pdname) or ('트렁크' in row_pdname) or ('남성' in row_pdname) or ('남아' in row_pdname)):\n",
    "            return 1\n",
    "        elif (row_pdgroup=='속옷') & (('드로즈' not in row_pdname) and ('트렁크' not in row_pdname) and ('남성' not in row_pdname) and ('남아' not in row_pdname)):\n",
    "            return 2\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "    df['underwear_sex'] = df.apply(lambda row: input_underwear_sex(row.pdgroup, row.pdname), axis = 1)\n",
    "    \n",
    "\n",
    "    # [KOSIS 데이터병합을 위한 컬럼]\n",
    "    df['index'] = df['datetime'].apply(lambda x: str(x)[:7])\n",
    "    \n",
    "\n",
    "    return df\n",
    "\n",
    "###//\n",
    "\n",
    "### [함수생성 = 데이터 병합] \n",
    "def merge_all(df, train = True):\n",
    "    \n",
    "    \n",
    "    # [상품카테고리, 네이버데이터랩 병합] \n",
    "    if train:\n",
    "        cat = load_categories(train=True)\n",
    "    else:\n",
    "        cat = load_categories(train=False)\n",
    "        \n",
    "    df = pd.concat([df, cat], axis = 1)\n",
    "    \n",
    "        \n",
    "    # [\"무형\" 데이터 제거] \n",
    "    df = df[df['pdgroup']!='무형']\n",
    "    \n",
    "    \n",
    "    # [KOSIS 데이터 병합] \n",
    "    sales_type_df = load_kosis('KOSIS_소매업태별_판매액.xlsx', '업태별')\n",
    "    retail_food_df = load_kosis('KOSIS_소매음식판매액지수_불변지수.xlsx', '업종별')\n",
    "    ind_type_df = load_kosis('KOSIS_소매업태별_판매액지수_불변지수.xlsx', '업태별')\n",
    "    ind_pd_kosis_df = load_kosis('KOSIS_업태별상품군_판매액지수_불변지수.xlsx', '업태별상품군').drop(['무점포 소매 총지수'], axis = 1)\n",
    "    \n",
    "    sales_type_df.columns = ['index', 'kos_nostore_sales']\n",
    "    retail_food_df.columns = ['index', 'kos_retail_sales_ind', 'kos_catering']\n",
    "    ind_type_df.columns = ['index', 'kos_online_shop', 'kos_homeshop']\n",
    "    \n",
    "    kosis_df_li = [df, sales_type_df, retail_food_df, ind_type_df] \n",
    "    df = reduce(lambda  left, right: pd.merge(left, right, on=['index']), kosis_df_li)\n",
    "    \n",
    "    def input_ind_pdtype_kosis(row): \n",
    "        cat_dict = {'의류': '의복', '속옷': '의복', '주방': '기타상품', '농수축': '음식료품', '이미용': '화장품', '가전': '가전제품', '생활용품': '기타상품',\n",
    "                   '건강기능': '음식료품', '잡화': '기타상품', '가구': '가구', '침구': '기타상품'}\n",
    "        pdgroup = row[df.columns.tolist().index('pdgroup')]\n",
    "        date = row[df.columns.tolist().index('index')]\n",
    "        row[df.columns.tolist().index('kos_pd_sales_ind')] = ind_pd_kosis_df[ind_pd_kosis_df['index']==date][cat_dict[pdgroup]].values[0]\n",
    "        return row\n",
    "    \n",
    "    df['kos_pd_sales_ind'] = [0]*len(df) \n",
    "    df = df.apply(input_ind_pdtype_kosis, axis = 1) \n",
    "    \n",
    "    \n",
    "    # [기상 데이터 병합]\n",
    "    if train:\n",
    "        wther = load_weather(train = True)\n",
    "    else:\n",
    "        wther = load_weather(train = False)\n",
    "    \n",
    "    df = pd.merge(df, wther, left_on = 'dt_YMD', right_on = 'date')\n",
    "    \n",
    "\n",
    "    # [마스크, 배송 데이터 병합]\n",
    "    parcel = load_parcel()\n",
    "    mask = load_mask()\n",
    "    \n",
    "    df = pd.merge(df, parcel, on = 'dt_YMD')\n",
    "    df = pd.merge(df, mask, on = 'dt_YMD')\n",
    "\n",
    "    return df\n",
    "\n",
    "### //"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 함수실행 - 데이터 불러오기 및 병합\n",
    "- train: 2019. 01 ~ 2019. 12.\n",
    "- test : 2020. 06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NSSHOP 제공데이터 load\n",
    "ns_train, ns_test = load_NS()\n",
    "\n",
    "# NSSHOP 제공데이터 preprocessing\n",
    "pp_train, pp_test = preprocess_NS(ns_train, hday_19), preprocess_NS(ns_test, hday_20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data.shape: (37368, 98) test_data.shape (2708, 98)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>duration</th>\n",
       "      <th>mthcode</th>\n",
       "      <th>pdcode</th>\n",
       "      <th>pdname</th>\n",
       "      <th>pdgroup</th>\n",
       "      <th>unitp</th>\n",
       "      <th>sales</th>\n",
       "      <th>mth</th>\n",
       "      <th>day</th>\n",
       "      <th>...</th>\n",
       "      <th>temp_gwangju</th>\n",
       "      <th>maxtemp_gwangju</th>\n",
       "      <th>mintemp_gwangju</th>\n",
       "      <th>dailycross_gwangju</th>\n",
       "      <th>precip_gwangju</th>\n",
       "      <th>humid_gwangju</th>\n",
       "      <th>cloud_gwangju</th>\n",
       "      <th>finedust</th>\n",
       "      <th>parcel</th>\n",
       "      <th>mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-01 06:00:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100346</td>\n",
       "      <td>201072</td>\n",
       "      <td>테이트 남성 셀린니트3종</td>\n",
       "      <td>의류</td>\n",
       "      <td>39900</td>\n",
       "      <td>2099000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65</td>\n",
       "      <td>7.9</td>\n",
       "      <td>38</td>\n",
       "      <td>3.0452</td>\n",
       "      <td>0.04095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-01 06:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>100346</td>\n",
       "      <td>201079</td>\n",
       "      <td>테이트 여성 셀린니트3종</td>\n",
       "      <td>의류</td>\n",
       "      <td>39900</td>\n",
       "      <td>4371000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.4</td>\n",
       "      <td>-2.3</td>\n",
       "      <td>4.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>65</td>\n",
       "      <td>7.9</td>\n",
       "      <td>38</td>\n",
       "      <td>3.0452</td>\n",
       "      <td>0.04095</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  duration  mthcode  pdcode         pdname pdgroup  \\\n",
       "0 2019-01-01 06:00:00      20.0   100346  201072  테이트 남성 셀린니트3종      의류   \n",
       "1 2019-01-01 06:00:00       NaN   100346  201079  테이트 여성 셀린니트3종      의류   \n",
       "\n",
       "   unitp      sales  mth  day  ...  temp_gwangju  maxtemp_gwangju  \\\n",
       "0  39900  2099000.0    1    1  ...           0.0              2.4   \n",
       "1  39900  4371000.0    1    1  ...           0.0              2.4   \n",
       "\n",
       "  mintemp_gwangju  dailycross_gwangju precip_gwangju  humid_gwangju  \\\n",
       "0            -2.3                 4.7            0.0             65   \n",
       "1            -2.3                 4.7            0.0             65   \n",
       "\n",
       "   cloud_gwangju  finedust  parcel     mask  \n",
       "0            7.9        38  3.0452  0.04095  \n",
       "1            7.9        38  3.0452  0.04095  \n",
       "\n",
       "[2 rows x 98 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>duration</th>\n",
       "      <th>mthcode</th>\n",
       "      <th>pdcode</th>\n",
       "      <th>pdname</th>\n",
       "      <th>pdgroup</th>\n",
       "      <th>unitp</th>\n",
       "      <th>sales</th>\n",
       "      <th>mth</th>\n",
       "      <th>day</th>\n",
       "      <th>...</th>\n",
       "      <th>temp_seoul</th>\n",
       "      <th>maxtemp_seoul</th>\n",
       "      <th>mintemp_seoul</th>\n",
       "      <th>dailycross_seoul</th>\n",
       "      <th>precip_seoul</th>\n",
       "      <th>humid_seoul</th>\n",
       "      <th>cloud_seoul</th>\n",
       "      <th>finedust</th>\n",
       "      <th>parcel</th>\n",
       "      <th>mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2020-06-01 06:20:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100650</td>\n",
       "      <td>201971</td>\n",
       "      <td>잭필드 남성  반팔셔츠 4종</td>\n",
       "      <td>의류</td>\n",
       "      <td>59800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>19.7</td>\n",
       "      <td>24.5</td>\n",
       "      <td>16.6</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>64</td>\n",
       "      <td>3.8</td>\n",
       "      <td>19</td>\n",
       "      <td>6.51407</td>\n",
       "      <td>1.85467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-06-01 06:40:00</td>\n",
       "      <td>20.0</td>\n",
       "      <td>100650</td>\n",
       "      <td>201971</td>\n",
       "      <td>잭필드 남성  반팔셔츠 4종</td>\n",
       "      <td>의류</td>\n",
       "      <td>59800</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>19.7</td>\n",
       "      <td>24.5</td>\n",
       "      <td>16.6</td>\n",
       "      <td>7.9</td>\n",
       "      <td>0.4</td>\n",
       "      <td>64</td>\n",
       "      <td>3.8</td>\n",
       "      <td>19</td>\n",
       "      <td>6.51407</td>\n",
       "      <td>1.85467</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime  duration  mthcode  pdcode           pdname pdgroup  \\\n",
       "0 2020-06-01 06:20:00      20.0   100650  201971  잭필드 남성  반팔셔츠 4종      의류   \n",
       "1 2020-06-01 06:40:00      20.0   100650  201971  잭필드 남성  반팔셔츠 4종      의류   \n",
       "\n",
       "   unitp  sales  mth  day  ...  temp_seoul  maxtemp_seoul mintemp_seoul  \\\n",
       "0  59800    NaN    6    1  ...        19.7           24.5          16.6   \n",
       "1  59800    NaN    6    1  ...        19.7           24.5          16.6   \n",
       "\n",
       "   dailycross_seoul precip_seoul  humid_seoul  cloud_seoul  finedust   parcel  \\\n",
       "0               7.9          0.4           64          3.8        19  6.51407   \n",
       "1               7.9          0.4           64          3.8        19  6.51407   \n",
       "\n",
       "      mask  \n",
       "0  1.85467  \n",
       "1  1.85467  \n",
       "\n",
       "[2 rows x 98 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 추가데이터셋과 NSSHOP 제공데이터 병합, Train, Test set 준비\n",
    "train_data = merge_all(pp_train, train = True)\n",
    "test_data = merge_all(pp_test, train = False) \n",
    "print('train_data.shape:', train_data.shape, 'test_data.shape', test_data.shape)\n",
    "\n",
    "display(train_data.head(2))\n",
    "display(test_data.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델적합을 위한 **변수선택과 파이프라인 함수 생성**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_features = ['unitp', 'jong', 'ratio',       # numerical\n",
    "                'kos_nostore_sales', 'kos_retail_sales_ind', 'kos_catering', 'kos_online_shop', 'kos_homeshop', 'kos_pd_sales_ind', \n",
    "                'parcel', 'mask', \n",
    "                'maxtemp_seoul', 'mintemp_seoul',  'precip_seoul', 'humid_seoul','dailycross_seoul','cloud_seoul', 'finedust', \n",
    "                'mthcode', 'pdcode', 'pdgroup', # categorical(one-hot)\n",
    "                'mth', 'day', 'hour', 'minute', 'wday', 'hday', 'hour_168', 'week_52', 'prime', 'mid_hour', 'mid_minute', 'zap_hour',\n",
    "                'sex', 'payment', 'bargain', 'sub_cate', \n",
    "                'part', 'junior', 'puma', 'dickies', 'uspa', 'season', 'yeonggwang', 'AAC', 'mask_pdn', 'hour_rank', 'underwear_sex',\n",
    "                'unitp_bin',                    # categorical(ordinal)\n",
    "                'sales']                        # target\n",
    "    \n",
    "numeric_features = ['unitp', 'jong', 'ratio', \n",
    "                   'kos_nostore_sales', 'kos_retail_sales_ind', 'kos_catering', 'kos_online_shop','kos_homeshop', 'kos_pd_sales_ind',\n",
    "                    'parcel', 'mask',\n",
    "                    'maxtemp_seoul', 'mintemp_seoul', 'dailycross_seoul', 'precip_seoul', 'humid_seoul', 'cloud_seoul', 'finedust']\n",
    "\n",
    "cat_ohe_features = ['junior', 'puma', 'dickies', 'uspa',\n",
    "                     'mthcode', 'pdcode', 'pdgroup', \n",
    "                    'mth', 'day', 'hour', 'minute', 'wday', 'hday', \n",
    "                      'hour_168', 'week_52', 'prime',\n",
    "                      'mid_hour', 'mid_minute', 'zap_hour',\n",
    "                    'sex', 'payment', 'bargain', 'sub_cate', \n",
    "                   'part' , 'season', 'yeonggwang', 'AAC', 'mask_pdn','hour_rank', 'underwear_sex']\n",
    "\n",
    "cat_ord_features = ['unitp_bin']\n",
    "\n",
    "def astype_cols(df):\n",
    "    \"\"\" 변수 데이터타입 변환 후 반환 \"\"\"\n",
    "    for numft in numeric_features:\n",
    "        df[numft] = df[numft].astype(np.float64)\n",
    "    for catoheft in cat_ohe_features:\n",
    "        df[catoheft] = df[catoheft].astype(str)\n",
    "    for catordft in cat_ord_features:\n",
    "        df[catordft] = df[catordft].astype(str)\n",
    "    return df\n",
    "\n",
    "def get_pipeline(use_features, numeric_features, cat_ohe_features, cat_ord_features):\n",
    "    \"\"\" Pipeline 반환 \"\"\"\n",
    "\n",
    "    prep_pipe = Pipeline(steps=[('preprocessor', ColumnTransformer(\n",
    "                                                transformers=[\n",
    "                                                ('num', StandardScaler(), numeric_features),\n",
    "                                                ('cat_ohe',  OneHotEncoder(handle_unknown='ignore'), cat_ohe_features),\n",
    "                                                ('cat_lbl', OrdinalEncoder(), cat_ord_features)])\n",
    "                                )])\n",
    "    return prep_pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  KNN Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6644000.09216122, 10574483.20619655,  9543920.6064579 , ...,\n",
       "        7203683.23936971,  5510860.64105574,  6351388.23719007])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "\n",
    "knn = KNeighborsRegressor(4, weights = 'distance')\n",
    "\n",
    "knn_pipe = get_pipeline(use_features, numeric_features, cat_ohe_features, cat_ord_features)\n",
    "\n",
    "# KNN - X, y\n",
    "X = train_data[use_features].dropna().drop(['sales'], axis = 1).reset_index(drop=True)\n",
    "y = train_data[use_features].dropna()['sales'].reset_index(drop=True)\n",
    "\n",
    "knnx = knn_pipe.fit_transform(astype_cols(X))\n",
    "knny = y\n",
    "\n",
    "# KNN - 학습\n",
    "knn.fit(knnx, np.log1p(knny))\n",
    "\n",
    "# KNN - 예측(매출액 결측치 대입)\n",
    "df_missing_sales = train_data[train_data['sales'].isnull()][use_features].drop(['sales'], axis = 1)\n",
    "df_missing_sales = astype_cols(df_missing_sales)\n",
    "\n",
    "imputed_sales = np.exp(knn.predict(knn_pipe.transform(df_missing_sales)))\n",
    "imputed_train_data = train_data[use_features].reset_index(drop=True)\n",
    "imputed_train_data.loc[imputed_train_data['sales'].isnull(),'sales'] = imputed_sales\n",
    "\n",
    "imputed_sales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 상품명(pdname) 벡터화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(train + test) 상품명 data 개수 : 40076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(40076, 1600)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tokens= [li for li in (train_data.pdname_token.tolist() + test_data.pdname_token.tolist())]\n",
    "print('(train + test) 상품명 data 개수 :',len(tokens))\n",
    "\n",
    "tfidf = TfidfVectorizer(\n",
    "    analyzer='word', lowercase = False, preprocessor= lambda x: ' '.join(x),\n",
    "    max_features = None, min_df = 10)\n",
    "\n",
    "name_tf = tfidf.fit_transform(tokens)\n",
    "name_tf.toarray().shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 학습을 위한 최종데이터셋 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_X_all shape : (37368, 2614) train_y shape : (37368,)\n",
      "test_X_all shape : (2708, 2614)\n"
     ]
    }
   ],
   "source": [
    "### [사용변수에서 상품코드와 마더코드 제외]\n",
    "use_features = [feature for feature in use_features if (feature!='pdcode') & (feature!='mthcode')]\n",
    "cat_ohe_features = [feature for feature in cat_ohe_features if (feature!='pdcode') & (feature!='mthcode')]\n",
    "\n",
    "\n",
    "### [데이터셋 X 변수들과  y(매출액) 정의]\n",
    "train_X = astype_cols(imputed_train_data[use_features].drop(['sales'], axis = 1).reset_index(drop=True))\n",
    "train_y = imputed_train_data['sales'].reset_index(drop=True)\n",
    "\n",
    "test_X = astype_cols(test_data[use_features].drop(['sales'], axis = 1))\n",
    "\n",
    "\n",
    "### [데이터셋 X 에 pipeline 실행]\n",
    "prep_pipe = get_pipeline(use_features, numeric_features, cat_ohe_features, cat_ord_features)\n",
    "prep_pipe.fit(pd.concat([train_X, test_X], axis = 0))\n",
    "\n",
    "train_X_pipe = prep_pipe.transform(train_X)\n",
    "test_X_pipe = prep_pipe.transform(test_X)\n",
    "\n",
    "\n",
    "### [데이터셋 X에 상품명벡터 병합]\n",
    "train_X_all = np.concatenate((train_X_pipe.toarray(), name_tf.toarray()[:train_X_pipe.shape[0],:]), axis =1)\n",
    "test_X_all = np.concatenate((test_X_pipe.toarray(), name_tf.toarray()[train_X_pipe.shape[0]:,:]), axis =1)\n",
    "\n",
    "print('train_X_all shape :', train_X_all.shape, 'train_y shape :', train_y.shape)\n",
    "print('test_X_all shape :', test_X_all.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 하이퍼파라미터 최적화 - 베이지안 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | min_sp... | n_esti... | num_le... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m-0.407   \u001b[0m | \u001b[0m 0.7596  \u001b[0m | \u001b[0m 0.3284  \u001b[0m | \u001b[0m 10.28   \u001b[0m | \u001b[0m 1.975   \u001b[0m | \u001b[0m 0.009645\u001b[0m | \u001b[0m 894.0   \u001b[0m | \u001b[0m 53.5    \u001b[0m | \u001b[0m 0.9082  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m-0.4235  \u001b[0m | \u001b[0m 0.4201  \u001b[0m | \u001b[0m 0.3091  \u001b[0m | \u001b[0m 7.804   \u001b[0m | \u001b[0m 6.006   \u001b[0m | \u001b[0m 0.08383 \u001b[0m | \u001b[0m 794.2   \u001b[0m | \u001b[0m 51.43   \u001b[0m | \u001b[0m 0.8562  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m-0.4264  \u001b[0m | \u001b[0m 0.6528  \u001b[0m | \u001b[0m 0.2845  \u001b[0m | \u001b[0m 5.401   \u001b[0m | \u001b[0m 6.229   \u001b[0m | \u001b[0m 0.04578 \u001b[0m | \u001b[0m 587.9   \u001b[0m | \u001b[0m 34.41   \u001b[0m | \u001b[0m 0.8585  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m-0.4243  \u001b[0m | \u001b[0m 0.3334  \u001b[0m | \u001b[0m 0.3502  \u001b[0m | \u001b[0m 5.446   \u001b[0m | \u001b[0m 4.023   \u001b[0m | \u001b[0m 0.03705 \u001b[0m | \u001b[0m 576.0   \u001b[0m | \u001b[0m 68.72   \u001b[0m | \u001b[0m 0.8887  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m-0.4252  \u001b[0m | \u001b[0m 0.318   \u001b[0m | \u001b[0m 0.3646  \u001b[0m | \u001b[0m 6.913   \u001b[0m | \u001b[0m 2.183   \u001b[0m | \u001b[0m 0.06479 \u001b[0m | \u001b[0m 553.8   \u001b[0m | \u001b[0m 55.37   \u001b[0m | \u001b[0m 0.8771  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m-0.4254  \u001b[0m | \u001b[0m 0.6897  \u001b[0m | \u001b[0m 0.3122  \u001b[0m | \u001b[0m 9.33    \u001b[0m | \u001b[0m 5.913   \u001b[0m | \u001b[0m 0.09295 \u001b[0m | \u001b[0m 999.1   \u001b[0m | \u001b[0m 98.6    \u001b[0m | \u001b[0m 0.897   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m-0.415   \u001b[0m | \u001b[0m 0.7605  \u001b[0m | \u001b[0m 0.2481  \u001b[0m | \u001b[0m 10.67   \u001b[0m | \u001b[0m 1.624   \u001b[0m | \u001b[0m 0.06034 \u001b[0m | \u001b[0m 895.6   \u001b[0m | \u001b[0m 56.19   \u001b[0m | \u001b[0m 0.8544  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m-0.4077  \u001b[0m | \u001b[0m 0.3     \u001b[0m | \u001b[0m 0.4     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 8.0     \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 1e+03   \u001b[0m | \u001b[0m 31.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m-0.4074  \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 0.4     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 8.0     \u001b[0m | \u001b[0m 0.001   \u001b[0m | \u001b[0m 873.5   \u001b[0m | \u001b[0m 31.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m-0.4123  \u001b[0m | \u001b[0m 0.7729  \u001b[0m | \u001b[0m 0.3908  \u001b[0m | \u001b[0m 5.247   \u001b[0m | \u001b[0m 1.247   \u001b[0m | \u001b[0m 0.02094 \u001b[0m | \u001b[0m 942.1   \u001b[0m | \u001b[0m 32.76   \u001b[0m | \u001b[0m 0.8952  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m-0.4272  \u001b[0m | \u001b[0m 0.3902  \u001b[0m | \u001b[0m 0.393   \u001b[0m | \u001b[0m 10.5    \u001b[0m | \u001b[0m 7.45    \u001b[0m | \u001b[0m 0.07923 \u001b[0m | \u001b[0m 936.9   \u001b[0m | \u001b[0m 32.51   \u001b[0m | \u001b[0m 0.8465  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m-0.4095  \u001b[0m | \u001b[0m 0.5699  \u001b[0m | \u001b[0m 0.384   \u001b[0m | \u001b[0m 11.98   \u001b[0m | \u001b[0m 1.749   \u001b[0m | \u001b[0m 0.01881 \u001b[0m | \u001b[0m 704.6   \u001b[0m | \u001b[0m 31.31   \u001b[0m | \u001b[0m 0.8902  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m-0.4136  \u001b[0m | \u001b[0m 0.4237  \u001b[0m | \u001b[0m 0.3137  \u001b[0m | \u001b[0m 7.887   \u001b[0m | \u001b[0m 1.847   \u001b[0m | \u001b[0m 0.03906 \u001b[0m | \u001b[0m 846.1   \u001b[0m | \u001b[0m 31.63   \u001b[0m | \u001b[0m 0.8306  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m-0.4179  \u001b[0m | \u001b[0m 0.6827  \u001b[0m | \u001b[0m 0.3754  \u001b[0m | \u001b[0m 5.012   \u001b[0m | \u001b[0m 1.016   \u001b[0m | \u001b[0m 0.03154 \u001b[0m | \u001b[0m 692.2   \u001b[0m | \u001b[0m 67.17   \u001b[0m | \u001b[0m 0.9004  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m-0.4155  \u001b[0m | \u001b[0m 0.5733  \u001b[0m | \u001b[0m 0.2239  \u001b[0m | \u001b[0m 7.938   \u001b[0m | \u001b[0m 4.854   \u001b[0m | \u001b[0m 0.04697 \u001b[0m | \u001b[0m 500.5   \u001b[0m | \u001b[0m 96.15   \u001b[0m | \u001b[0m 0.945   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m-0.4228  \u001b[0m | \u001b[0m 0.6674  \u001b[0m | \u001b[0m 0.2399  \u001b[0m | \u001b[0m 5.244   \u001b[0m | \u001b[0m 1.063   \u001b[0m | \u001b[0m 0.08667 \u001b[0m | \u001b[0m 889.7   \u001b[0m | \u001b[0m 53.44   \u001b[0m | \u001b[0m 0.9235  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m-0.4143  \u001b[0m | \u001b[0m 0.7299  \u001b[0m | \u001b[0m 0.2766  \u001b[0m | \u001b[0m 11.64   \u001b[0m | \u001b[0m 1.056   \u001b[0m | \u001b[0m 0.05387 \u001b[0m | \u001b[0m 898.2   \u001b[0m | \u001b[0m 33.26   \u001b[0m | \u001b[0m 0.8924  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m-0.4193  \u001b[0m | \u001b[0m 0.4431  \u001b[0m | \u001b[0m 0.3817  \u001b[0m | \u001b[0m 8.944   \u001b[0m | \u001b[0m 6.489   \u001b[0m | \u001b[0m 0.04336 \u001b[0m | \u001b[0m 501.3   \u001b[0m | \u001b[0m 33.39   \u001b[0m | \u001b[0m 0.8254  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m-0.4124  \u001b[0m | \u001b[0m 0.734   \u001b[0m | \u001b[0m 0.3476  \u001b[0m | \u001b[0m 5.346   \u001b[0m | \u001b[0m 1.402   \u001b[0m | \u001b[0m 0.02738 \u001b[0m | \u001b[0m 996.5   \u001b[0m | \u001b[0m 54.42   \u001b[0m | \u001b[0m 0.9684  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m-0.4206  \u001b[0m | \u001b[0m 0.4741  \u001b[0m | \u001b[0m 0.3919  \u001b[0m | \u001b[0m 11.62   \u001b[0m | \u001b[0m 7.552   \u001b[0m | \u001b[0m 0.04051 \u001b[0m | \u001b[0m 650.6   \u001b[0m | \u001b[0m 98.43   \u001b[0m | \u001b[0m 0.9678  \u001b[0m |\n",
      "| \u001b[95m 21      \u001b[0m | \u001b[95m-0.4048  \u001b[0m | \u001b[95m 0.6505  \u001b[0m | \u001b[95m 0.2661  \u001b[0m | \u001b[95m 11.61   \u001b[0m | \u001b[95m 7.464   \u001b[0m | \u001b[95m 0.0162  \u001b[0m | \u001b[95m 853.1   \u001b[0m | \u001b[95m 54.11   \u001b[0m | \u001b[95m 0.9499  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m-0.4193  \u001b[0m | \u001b[0m 0.4819  \u001b[0m | \u001b[0m 0.3682  \u001b[0m | \u001b[0m 11.87   \u001b[0m | \u001b[0m 7.524   \u001b[0m | \u001b[0m 0.04281 \u001b[0m | \u001b[0m 719.0   \u001b[0m | \u001b[0m 62.84   \u001b[0m | \u001b[0m 0.8881  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m-0.4085  \u001b[0m | \u001b[0m 0.5984  \u001b[0m | \u001b[0m 0.2616  \u001b[0m | \u001b[0m 11.92   \u001b[0m | \u001b[0m 7.19    \u001b[0m | \u001b[0m 0.02891 \u001b[0m | \u001b[0m 652.7   \u001b[0m | \u001b[0m 52.16   \u001b[0m | \u001b[0m 0.9292  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m-0.4243  \u001b[0m | \u001b[0m 0.79    \u001b[0m | \u001b[0m 0.3151  \u001b[0m | \u001b[0m 11.84   \u001b[0m | \u001b[0m 7.742   \u001b[0m | \u001b[0m 0.0876  \u001b[0m | \u001b[0m 780.8   \u001b[0m | \u001b[0m 33.51   \u001b[0m | \u001b[0m 0.9227  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m-0.4084  \u001b[0m | \u001b[0m 0.7331  \u001b[0m | \u001b[0m 0.3833  \u001b[0m | \u001b[0m 11.87   \u001b[0m | \u001b[0m 7.969   \u001b[0m | \u001b[0m 0.01036 \u001b[0m | \u001b[0m 861.6   \u001b[0m | \u001b[0m 39.12   \u001b[0m | \u001b[0m 0.9611  \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m-0.416   \u001b[0m | \u001b[0m 0.6674  \u001b[0m | \u001b[0m 0.3678  \u001b[0m | \u001b[0m 5.23    \u001b[0m | \u001b[0m 7.628   \u001b[0m | \u001b[0m 0.0103  \u001b[0m | \u001b[0m 681.8   \u001b[0m | \u001b[0m 33.52   \u001b[0m | \u001b[0m 0.9559  \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m-0.4276  \u001b[0m | \u001b[0m 0.7794  \u001b[0m | \u001b[0m 0.3456  \u001b[0m | \u001b[0m 10.98   \u001b[0m | \u001b[0m 1.445   \u001b[0m | \u001b[0m 0.09803 \u001b[0m | \u001b[0m 779.6   \u001b[0m | \u001b[0m 99.92   \u001b[0m | \u001b[0m 0.897   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m-0.4182  \u001b[0m | \u001b[0m 0.7632  \u001b[0m | \u001b[0m 0.364   \u001b[0m | \u001b[0m 11.66   \u001b[0m | \u001b[0m 2.144   \u001b[0m | \u001b[0m 0.03309 \u001b[0m | \u001b[0m 550.2   \u001b[0m | \u001b[0m 99.17   \u001b[0m | \u001b[0m 0.843   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m-0.419   \u001b[0m | \u001b[0m 0.5369  \u001b[0m | \u001b[0m 0.3653  \u001b[0m | \u001b[0m 5.015   \u001b[0m | \u001b[0m 2.258   \u001b[0m | \u001b[0m 0.04604 \u001b[0m | \u001b[0m 999.2   \u001b[0m | \u001b[0m 32.13   \u001b[0m | \u001b[0m 0.833   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m-0.4061  \u001b[0m | \u001b[0m 0.4229  \u001b[0m | \u001b[0m 0.3821  \u001b[0m | \u001b[0m 11.28   \u001b[0m | \u001b[0m 2.236   \u001b[0m | \u001b[0m 0.00105 \u001b[0m | \u001b[0m 651.1   \u001b[0m | \u001b[0m 31.49   \u001b[0m | \u001b[0m 0.9575  \u001b[0m |\n",
      "=========================================================================================================================\n",
      "{'colsample_bytree': 0.6504924747138918, 'learning_rate': 0.2660968647756925, 'max_depth': 11.613581978182857, 'min_child_weight': 7.464060154608676, 'min_split_gain': 0.016196746228341233, 'n_estimators': 853.1367164873984, 'num_leaves': 54.111318230085516, 'subsample': 0.949905431423709}\n"
     ]
    }
   ],
   "source": [
    "def bayesion_opt_lgbm(X, y, init_iter=3, n_iters=7, random_state=11, seed = 101, num_iterations = 100):\n",
    "    dtrain = lightgbm.Dataset(data=X, label=y)\n",
    "  \n",
    "    def hyp_lgbm(num_leaves, max_depth, min_split_gain, min_child_weight, \\\n",
    "                 learning_rate, colsample_bytree, subsample, n_estimators):\n",
    "\n",
    "        params = {'application':'regression','num_iterations': num_iterations,\n",
    "                  'early_stopping_round': 50,\n",
    "                'metric':'rmse'} # Default parameters\n",
    "        params[\"num_leaves\"] = int(round(num_leaves))\n",
    "        params['max_depth'] = int(round(max_depth))\n",
    "        params['min_split_gain'] = min_split_gain\n",
    "        params['min_child_weight'] = int(min_child_weight)\n",
    "        params['learning_rate'] = learning_rate,\n",
    "        params['colsample_bytree']= colsample_bytree\n",
    "        params['subsample']= subsample\n",
    "        params['n_estimators']= int(n_estimators)\n",
    "        \n",
    "        cv_results = lightgbm.cv(params, dtrain, nfold = 5, seed = seed, categorical_feature=[], stratified=False,\n",
    "                          verbose_eval =None)\n",
    "        return  (-1.0 * np.array(cv_results['rmse-mean'])).max()\n",
    "    \n",
    "\n",
    "    pds = {'num_leaves': (31, 100),\n",
    "            'max_depth': (5, 12),\n",
    "            'min_split_gain': (0.001, 0.1),\n",
    "            'min_child_weight': (10, 25),\n",
    "           'learning_rate':(0.2, 0.4),\n",
    "           'min_child_weight':(1, 8),\n",
    "           'colsample_bytree':(0.3, 0.8),\n",
    "           'subsample': (0.8, 1),\n",
    "           'n_estimators': (500, 1000)\n",
    "            }\n",
    "\n",
    "    optimizer = BayesianOptimization(hyp_lgbm, pds, random_state=random_state)\n",
    "    optimizer.maximize(init_points=init_iter, n_iter=n_iters, acq = 'ei')\n",
    "    print(optimizer.max['params'])\n",
    "    return optimizer.res\n",
    "\n",
    "res = bayesion_opt_lgbm(train_X_all, np.log1p(train_y), init_iter=5, n_iters=25, random_state=77, seed = 101, num_iterations = 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델학습 - **LightGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMRegressor(boosting_type='gbdt', class_weight=None, colsample_bytree=0.7,\n",
       "              gamma=1, importance_type='split', learning_rate=0.32,\n",
       "              max_depth=10, min_child_samples=20, min_child_weight=0.001,\n",
       "              min_split_gain=0.0, n_estimators=900, n_jobs=-1, num_leaves=31,\n",
       "              objective=None, random_state=None, reg_alpha=0.0, reg_lambda=0.0,\n",
       "              silent=True, subsample=1.0, subsample_for_bin=200000,\n",
       "              subsample_freq=0)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### [모델 학습]\n",
    "model = LGBMRegressor(n_estimators = 900, \n",
    "                      max_depth = 10, \n",
    "                      learning_rate= 0.32,\n",
    "                      colsample_bytree = 0.7,\n",
    "                     gamma = 1\n",
    "                     )\n",
    "\n",
    "model.fit(train_X_all, np.log1p(train_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 제출파일 생성 - (2020. 06) 테스트 데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data 개수: 2708 \n",
      "test 예측 data 개수: 2708\n"
     ]
    }
   ],
   "source": [
    "test_pred = np.expm1(model.predict(test_X_all))\n",
    "print('test data 개수:', test_data.shape[0], '\\ntest 예측 data 개수:', test_pred.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['sales'] = test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = test_data[['datetime', 'duration', 'mthcode', 'pdcode', 'pdname', 'pdgroup', 'unitp', 'sales']]\n",
    "submission.columns = ['방송일시', '노출(분)', '마더코드', '상품코드', '상품명', '상품군', '판매단가', '취급액']\n",
    "submission.to_excel('데이터분석분야_챔피언리그_InsightOut_평가데이터답안파일.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_kernel",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
